{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "#学习率，学习率一般为0.01，0.1等等较小的数，为了在梯度下降求解时避免错过最优解\n",
    "LR = 0.001\n",
    "EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\data\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [1:31:42, ?it/s]\n",
      "0it [25:49, ?it/s]\n",
      "0it [04:16, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\data\\MNIST\\raw\n",
      "Using downloaded and verified file: .\\data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\data\\MNIST\\raw\n",
      "Using downloaded and verified file: .\\data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting .\\data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='.\\data', \n",
    "                                        train=True, \n",
    "                                        transform=torchvision.transforms.ToTensor(),  \n",
    "                                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2 )\n",
    "#每个batch_size的shape为[64, 1, 28, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集操作和上面注释一样\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='.\\data',\n",
    "    train = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33398\\.conda\\envs\\Aliyun\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\Users\\33398\\.conda\\envs\\Aliyun\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\Users\\33398\\.conda\\envs\\Aliyun\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000]/255.0\n",
    "#标签取前2000\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #前面都是规定结构\n",
    "        #第一个卷积层，这里使用快速搭建发搭建网络\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,#灰度图，channel为一\n",
    "                out_channels=16,#输出channels自己设定\n",
    "                kernel_size=3,#卷积核大小\n",
    "                stride=1,#步长\n",
    "                padding=1#padding=（kernel_size-stride）/2   往下取整\n",
    "            ),\n",
    "            nn.ReLU(),#激活函数，线性转意识到非线性空间\n",
    "            nn.MaxPool2d(kernel_size=2)#池化操作，降维，取其2x2窗口最大值代表此窗口，因此宽、高减半，channel不变\n",
    "        )\n",
    "        #此时shape为[16, 14, 14]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        #此时shape为[32, 7, 7]\n",
    "        #定义全连接层，十分类，并且全连接接受两个参数，因此为[32*7*7, 10]\n",
    "        self.prediction = nn.Linear(32*7*7, 10)\n",
    "        #前向传播过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.prediction(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "\n",
    "#大数据常用Adam优化器，参数需要model的参数，以及学习率\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), LR)\n",
    "#定义损失函数，交叉熵\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 |test accuracy：0.1490\n",
      "epoch: 0 |test accuracy：0.8415\n",
      "epoch: 0 |test accuracy：0.8905\n",
      "epoch: 0 |test accuracy：0.9155\n",
      "epoch: 0 |test accuracy：0.9255\n",
      "epoch: 0 |test accuracy：0.9335\n",
      "epoch: 0 |test accuracy：0.9465\n",
      "epoch: 0 |test accuracy：0.9460\n",
      "epoch: 0 |test accuracy：0.9505\n",
      "epoch: 0 |test accuracy：0.9535\n",
      "epoch: 0 |test accuracy：0.9545\n",
      "epoch: 0 |test accuracy：0.9630\n",
      "epoch: 0 |test accuracy：0.9645\n",
      "epoch: 0 |test accuracy：0.9660\n",
      "epoch: 0 |test accuracy：0.9670\n",
      "epoch: 0 |test accuracy：0.9710\n",
      "epoch: 0 |test accuracy：0.9675\n",
      "epoch: 0 |test accuracy：0.9730\n",
      "epoch: 0 |test accuracy：0.9715\n"
     ]
    }
   ],
   "source": [
    "#训练阶段\n",
    "for epoch in range(EPOCH):\n",
    "    #step,代表现在第几个batch_size\n",
    "    #batch_x 训练集的图像\n",
    "    #batch_y 训练集的标签\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        #model只接受Variable的数据，因此需要转化\n",
    "        b_x = Variable(batch_x)\n",
    "        b_y = Variable(batch_y)\n",
    "        #将b_x输入到model得到返回值\n",
    "        output = cnn(b_x)\n",
    "        #计算误差\n",
    "        loss = loss_func(output, b_y)\n",
    "        #将梯度变为0\n",
    "        optimizer.zero_grad()\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #优化参数\n",
    "        optimizer.step()\n",
    "        #打印操作，用测试集检验是否预测准确\n",
    "        if step%50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            #squeeze将维度值为1的除去，例如[64, 1, 28, 28]，变为[64, 28, 28]\n",
    "            pre_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            #总预测对的数除总数就是对的概率\n",
    "            accuracy = float((pre_y == test_y).sum()) / float(test_y.size(0))\n",
    "            print(\"epoch:\", epoch,  \"|test accuracy：%.4f\" %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.7203, -17.8591,   0.8596,  -4.9627,  -8.4965,  -0.9482,  -6.5672,\n",
      "          -3.4619,  -2.5276,  -1.6643],\n",
      "        [ -3.4920,   7.6434,  -3.6701,  -3.8393,   0.3460,  -4.8533,  -2.6877,\n",
      "          -2.5776,  -1.0976,  -4.4321],\n",
      "        [ -2.9913,   7.5144,  -2.1815,  -3.9086,  -1.0041,  -4.7809,  -2.9428,\n",
      "          -2.8509,  -1.3397,  -4.8424],\n",
      "        [ -4.7841, -14.9725,  -4.0071,  -5.3980, -14.6892,  -3.2255,  -5.5932,\n",
      "          -9.1255,  -0.0449,  -4.9689],\n",
      "        [-14.1664,  -6.5079,  -8.0963,  -4.5434,   8.9957,  -4.2064,  -7.1382,\n",
      "          -5.3441,   0.4848,  -0.9329],\n",
      "        [ 12.9074, -16.8930,  -3.6951,  -9.8010, -16.5737,  -2.6237,   1.5323,\n",
      "         -11.9687,  -2.6938,  -4.3762],\n",
      "        [ -3.9486,   5.7839,  -0.5935,  -2.7641,  -2.2659,  -6.7892,  -5.8832,\n",
      "          -1.7627,  -0.6090,  -2.7270],\n",
      "        [ -6.3408,  -4.0967,  -3.2013,  -1.8224,  -5.2719,  -2.6525, -17.6906,\n",
      "           7.5299,  -5.0006,   3.3216],\n",
      "        [-11.7372,  -7.9817,  -8.2474,  -7.7006,  12.1811,  -6.3819,  -8.2298,\n",
      "          -4.4620,  -1.5093,  -1.3754],\n",
      "        [ -8.2923,  -2.6569,   9.5341,   0.2181, -12.1457, -12.3849, -13.8027,\n",
      "          -0.8902,  -5.0686, -14.9469],\n",
      "        [ -9.3979,  -6.3759,  -5.6047,   6.9316, -12.2212,   2.6156, -11.0155,\n",
      "         -10.0688,  -0.8332,  -1.6668],\n",
      "        [ -5.6250,  -9.0272,  -0.6133,  -0.0417,  -8.3602,  -5.1717,  -7.6055,\n",
      "         -13.5507,   5.7495,  -4.1989],\n",
      "        [ -9.0720,  -9.0195,  -5.8354,   7.6003, -15.2464,  -0.6407, -23.3476,\n",
      "          -4.6867,  -5.0468,   0.4976],\n",
      "        [ -6.7609,  -6.3102,   9.9387,  -1.3210, -13.6925, -11.4673, -11.6729,\n",
      "          -8.2304,  -1.5930, -13.9550],\n",
      "        [ -7.7228,  -5.7554,   9.7099,  -1.4831, -13.4200, -10.2201, -14.2602,\n",
      "          -8.2439,  -1.3430, -12.8660],\n",
      "        [ -4.7487, -11.4086,  -0.5086,  -0.1920, -15.7774,  -4.4502, -18.5572,\n",
      "          10.0120,  -7.7841,   1.7553],\n",
      "        [-11.5154,  -8.3564,  -2.8390,  -3.6215,  -1.6131,  -4.2536, -12.7509,\n",
      "          -3.7298,  -0.3863,   6.6274],\n",
      "        [ -4.5101, -11.9036,  -0.3636,   8.9721, -18.6485,  -1.3544, -16.9191,\n",
      "         -14.2860,  -2.4467,  -5.4994],\n",
      "        [  8.7785, -12.8811,  -3.7693, -10.8357, -12.8721,  -6.3225,  -4.7887,\n",
      "          -6.0981,  -2.7335,  -5.2597],\n",
      "        [  9.2859, -12.1487,  -2.8142, -10.8381, -13.2296,  -6.8536,  -1.5763,\n",
      "         -10.2899,  -3.5864,  -9.0751],\n",
      "        [ -5.8443,  -9.4064,   1.0702,   8.3203, -16.7836,  -4.9182, -14.3948,\n",
      "          -7.0640,  -2.5399,  -3.5717],\n",
      "        [ -3.8963,  -6.0941,  -1.2799,  -1.7388,  -6.5633,  -3.6294,  -7.8897,\n",
      "          -6.3971,   5.6265,  -0.6977],\n",
      "        [ 10.3584, -16.2466,  -2.4489,  -9.9265, -12.8469,  -4.8611,   0.1956,\n",
      "         -11.7116,  -0.7746,  -4.4498],\n",
      "        [ -2.5584, -13.8452,  -4.0063, -12.2376, -12.8935,  -3.4163,   5.1473,\n",
      "         -19.0552,  -0.3664,  -9.8803],\n",
      "        [-16.9386, -18.4221,  -1.2544,  -0.2102, -19.1481,   7.6911, -15.1407,\n",
      "         -15.2887,   2.4074,  -7.8284],\n",
      "        [ -5.4144,   5.3199,  -4.4062,  -2.5521,   0.8632,  -3.6561,  -6.8495,\n",
      "          -2.5659,  -0.7448,  -1.0106],\n",
      "        [ -4.8035,   7.4721,  -3.0881,  -3.8147,   0.4287,  -8.0452,  -5.2129,\n",
      "          -0.5607,  -1.2702,  -5.5340],\n",
      "        [-10.8501,  -9.4108,  -5.4485,  10.6800, -18.5732,   1.2713, -16.1392,\n",
      "         -13.4294,  -3.5577,  -6.1459],\n",
      "        [ -4.0154,   7.6799,  -2.9754,  -3.7981,  -1.4570,  -5.4252,  -3.4080,\n",
      "          -3.2723,  -1.6938,  -6.6340],\n",
      "        [ -8.9591, -12.8002,  -8.1841,   7.8207, -12.7866,   2.4954, -13.9441,\n",
      "         -13.3385,  -3.1006,  -1.7812],\n",
      "        [ -5.1719, -11.9499,  -5.9828,  -4.7304,  -1.5895,  -4.4471,  -9.2291,\n",
      "           0.4059,  -3.6791,   7.6406],\n",
      "        [  9.0306, -15.9822,  -4.9463,  -9.2651, -18.3113,  -3.4950,  -5.2599,\n",
      "         -12.1604,  -4.3212,  -7.4881]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aliyun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
